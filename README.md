# GenAI Stack - No-Code Workflow Builder

A full-stack No-Code/Low-Code web application that enables users to visually create and interact with intelligent workflows using drag-and-drop components.

## ğŸš€ Features

- **Visual Workflow Builder** - Drag-and-drop interface built with React Flow
- **4 Core Components**:
  - **User Query** - Entry point for user input
  - **Knowledge Base** - PDF upload, text extraction, vector embeddings, RAG retrieval
  - **LLM Engine** - OpenAI GPT integration with custom prompts and web search
  - **Output** - Display final results
- **Chat Interface** - Test workflows with interactive chat
- **Workflow Persistence** - Save and load workflows from PostgreSQL
- **Chat History** - Persistent conversation history
- **Document Processing** - PDF text extraction with PyMuPDF and OpenAI embeddings
- **Vector Search** - ChromaDB for semantic search
- **Web Search** - SerpAPI integration for real-time information

## ğŸ›  Tech Stack

### Frontend
- **React** + **Vite** - Fast modern development
- **React Flow** - Visual workflow canvas
- **TailwindCSS** - Styling with custom design system
- **Zustand** - State management
- **React Query** - API data fetching
- **Axios** - HTTP client
- **Lucide Icons** - Icon library

### Backend
- **FastAPI** - High-performance Python API
- **PostgreSQL** - Relational database
- **SQLAlchemy** - ORM
- **ChromaDB** - Vector store
- **OpenAI** - GPT-4 and text embeddings
- **SerpAPI** - Web search
- **PyMuPDF** - PDF text extraction

### Deployment
- **Docker** + **Docker Compose** - Containerization
- **Nginx** - Frontend serving and reverse proxy

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- OpenAI API key
- SerpAPI key (for web search feature)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
cd PlanetAiAssignment
```

### 2. Configure Environment Variables

Create `.env` file in the root directory:

```bash
cp .env.example .env
```

Edit `.env` and add your API keys:

```env
OPENAI_API_KEY=your_openai_api_key_here
SERPAPI_API_KEY=your_serpapi_key_here
```

Also create backend `.env`:

```bash
cp backend/.env.example backend/.env
```

Edit `backend/.env` with the same API keys.

### 3. Run with Docker Compose

```bash
docker-compose up --build
```

This will start:
- **Frontend** - http://localhost:80
- **Backend API** - http://localhost:8000
- **PostgreSQL** - localhost:5432
- **API Docs** - http://localhost:8000/docs

### 4. Access the Application

Open your browser and navigate to:
- **Application**: http://localhost:80
- **API Documentation**: http://localhost:8000/docs

## ğŸ“– Usage Guide

### Creating Your First Workflow

1. **Create a New Stack**
   - Click "+ New Stack" button
   - Enter name (e.g., "Chat With PDF")
   - Enter description
   - Click "Create"

2. **Build Your Workflow**
   - Drag components from the left sidebar onto the canvas
   - Connect components by dragging from output handle to input handle
   - Example flow: `User Query â†’ Knowledge Base â†’ LLM Engine â†’ Output`

3. **Configure Components**
   - Click on any component to open configuration panel
   - **Knowledge Base**: Upload PDF documents
   - **LLM Engine**: Select model (GPT-4o-Mini), set temperature, enable web search
   - Configure custom prompts with placeholders: `{query}`, `{context}`

4. **Save Workflow**
   - Click "Save" button in top right

5. **Test with Chat**
   - Click "Chat with Stack" button
   - Enter your query in the chat interface
   - View AI-generated responses

### Example Workflows

#### 1. Simple AI Chat
```
User Query â†’ LLM Engine â†’ Output
```

#### 2. Document Q&A (RAG)
```
User Query â†’ Knowledge Base (with uploaded PDFs) â†’ LLM Engine â†’ Output
```

#### 3. Web-Enhanced Chat
```
User Query â†’ LLM Engine (with web search enabled) â†’ Output
```

## ğŸ— Project Structure

```
PlanetAiAssignment/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py  # Document upload/management
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows.py  # Workflow CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py       # Chat execution
â”‚   â”‚   â”‚   â””â”€â”€ health.py     # Health check
â”‚   â”‚   â”œâ”€â”€ components/       # Workflow components
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user_query.py
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledgebase.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_engine.py
â”‚   â”‚   â”‚   â””â”€â”€ output.py
â”‚   â”‚   â”œâ”€â”€ database/         # Database models & schemas
â”‚   â”‚   â”œâ”€â”€ vector_store/     # ChromaDB client
â”‚   â”‚   â””â”€â”€ workflow/         # Workflow validator & executor
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ services/        # API services
â”‚   â”‚   â”œâ”€â”€ store/           # State management
â”‚   â”‚   â”œâ”€â”€ App.jsx          # Main app component
â”‚   â”‚   â””â”€â”€ index.css        # Global styles
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ”§ Development

### Backend Development

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy and configure .env
cp .env.example .env
# Edit .env with your API keys

# Run development server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Development

```bash
cd frontend

# Install dependencies
npm install

# Copy and configure .env
cp .env.example .env

# Run development server
npm run dev
```

Visit http://localhost:5173

### Database Setup

The application automatically creates database tables on startup. To manually initialize:

```python
from app.database.connection import init_db
init_db()
```

## ğŸ—„ Database Schema

### Tables

- **documents** - Uploaded file metadata and processing status
- **workflows** - Workflow definitions (nodes, edges, validation status)
- **chat_sessions** - Chat conversation sessions
- **chat_messages** - Individual messages in conversations

## ğŸ”Œ API Endpoints

### Workflows
- `GET /workflows/` - List all workflows
- `POST /workflows/` - Create workflow
- `GET /workflows/{id}` - Get workflow
- `PUT /workflows/{id}` - Update workflow
- `DELETE /workflows/{id}` - Delete workflow
- `POST /workflows/{id}/validate` - Validate workflow

### Documents
- `GET /documents/` - List documents
- `POST /documents/upload` - Upload PDF
- `DELETE /documents/{id}` - Delete document

### Chat
- `POST /chat/execute` - Execute workflow with query
- `GET /chat/sessions/{id}` - Get chat session with messages

### Health
- `GET /health/` - Check system health

Full API documentation available at http://localhost:8000/docs

## ğŸ³ Docker Commands

```bash
# Build and start all services
docker-compose up --build

# Start in detached mode
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Remove volumes (clean slate)
docker-compose down -v

# Rebuild specific service
docker-compose build backend
docker-compose up backend
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
pytest tests/
```

### Manual Testing

1. Test document upload in API docs: http://localhost:8000/docs
2. Create a workflow via UI
3. Upload a PDF document
4. Configure Knowledge Base component to use uploaded document
5. Test chat with questions about the document

## ğŸ” Troubleshooting

### Database Connection Errors
- Ensure PostgreSQL container is running: `docker-compose ps`
- Check database logs: `docker-compose logs postgres`

### API Key Errors
- Verify `.env` file exists and contains valid API keys
- Restart containers after updating `.env`: `docker-compose restart`

### Frontend Build Errors
- Clear node_modules: `rm -rf frontend/node_modules`
- Reinstall: `cd frontend && npm install`

### ChromaDB Errors
- Clear vector store: `docker-compose down -v`
- Restart: `docker-compose up`

## ğŸ“ Environment Variables

### Backend (.env)
```env
DATABASE_URL=postgresql://genai_user:genai_password@localhost:5432/genai_stack
OPENAI_API_KEY=your_key_here
SERPAPI_API_KEY=your_key_here
CHROMA_PERSIST_DIR=./chroma_data
DEBUG=True
```

### Frontend (.env)
```env
VITE_API_URL=http://localhost:8000
```

## ğŸ¨ Design Reference

The UI follows the Figma design with:
- **Primary Color**: #4CAF50 (Green)
- **Secondary Color**: #2196F3 (Blue)
- **Typography**: Inter font family
- **Component Cards**: Rounded corners with subtle shadows
- **Chat Interface**: User messages in light blue, AI responses in white

## ğŸš§ Future Enhancements

- [ ] User authentication and authorization
- [ ] Workflow templates library
- [ ] Real-time collaboration
- [ ] More component types (API calls, data transformations)
- [ ] Workflow scheduling and automation
- [ ] Analytics and monitoring dashboard
- [ ] Export/import workflows
- [ ] Version control for workflows

## ğŸ“„ License

This project is created as an assignment for Planet AI.

## ğŸ‘¥ Authors

Built with â¤ï¸ for the Planet AI Full-Stack Engineer assignment

## ğŸ™ Acknowledgments

- OpenAI for GPT and embeddings API
- React Flow for the excellent workflow visualization library
- FastAPI for the modern Python web framework
- The open-source community

---

**Need Help?** Check the API documentation at http://localhost:8000/docs or review the implementation plan in the `/brain` artifacts directory.
